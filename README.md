# ğŸ“© SMS Spam Detector â€“ NLP & Metadata Machine Learning Project

A complete end-to-end machine learning pipeline for detecting spam messages using both natural language processing (NLP) and engineered metadata features. The project achieves **99.89% F1-score** using Logistic Regression with CountVectorizer and SMOTE oversampling.

---

## ğŸš€ Project Overview

This project tackles the **SMS Spam Classification** problem using a dataset of 5,574 messages labeled as either **ham (legitimate)** or **spam**. It involves:

- ğŸ§¹ Data Cleaning & Deduplication  
- ğŸ§  Feature Engineering (Text + Metadata)  
- ğŸ“Š Exploratory Data Analysis (EDA)  
- ğŸ§¾ Text Vectorization using CountVectorizer and TF-IDF  
- ğŸ¤– Modeling with multiple ML algorithms  
- ğŸ”§ Hyperparameter Tuning with Grid & Random Search  
- âœ… Final Deployment Testing with live message predictions

---

## ğŸ“ Dataset

- **Source:** [UCI SMS Spam Collection](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)
- **Size:** 5,574 messages  
- **Columns:**
  - `v1` â€” label (ham or spam)
  - `v2` â€” SMS text message

---

## ğŸ§  Feature Engineering

In addition to text preprocessing, the following metadata features were engineered:

| Feature Name         | Description                                         |
|----------------------|-----------------------------------------------------|
| `message_len`        | Length of the message (characters)                 |
| `word_count`         | Total word count                                   |
| `digit_count`        | Number of digits                                   |
| `ex_count`           | Number of exclamation marks                        |
| `has_link`           | Whether a link is present (1/0)                    |
| `punct_percent`      | Punctuation-to-character ratio                     |
| `capitalized_count`  | Number of fully capitalized words                  |
| `capitalized_ratio`  | Ratio of capitalized words to total words          |
| `free/win/..._count` | Keyword frequencies for 7 spam trigger words       |
| `unique_word_count`  | Number of unique words                             |
| `avg_word_length`    | Average word length                                |

---

## âœ¨ Exploratory Data Analysis (EDA)

- ğŸ“¦ Distribution of Ham vs Spam
- ğŸ“ˆ Feature histograms and boxplots
- â˜ï¸ WordClouds for Spam and Ham
- ğŸ”— Insights on links, punctuation, keyword triggers

---

## ğŸ› ï¸ Modeling & Evaluation

### âœ… Models Used:

- `Multinomial Naive Bayes`
- `Complement Naive Bayes`
- `Logistic Regression` (best)

### âœ… Vectorizers:

- `TF-IDF`
- `CountVectorizer` (best)

### ğŸ§ª Results (Before Tuning):

| Vectorizer | Model             | Accuracy | Precision | Recall | F1 Score | AUC   |
|------------|-------------------|----------|-----------|--------|----------|--------|
| CountVec   | LogisticRegression| 0.9978   | 0.9989    | 0.9967 | 0.9978   | 1.0000 |
| CountVec   | MultinomialNB     | 0.9923   | 0.9871    | 0.9978 | 0.9925   | 0.9998 |
| CountVec   | ComplementNB      | 0.9923   | 0.9871    | 0.9978 | 0.9925   | 0.9998 |

### ğŸ§ª After Hyperparameter Tuning:

| Model             | Accuracy | Precision | Recall | F1 Score | AUC   | Best Params |
|------------------|----------|-----------|--------|----------|--------|-------------|
| LogisticRegression | 0.9989 | 0.9989    | 0.9989 | 0.9989   | 1.0    | `C=10`, solver=`liblinear` |
| MultinomialNB     | 0.9950   | 0.9903    | 1.0000 | 0.9951   | 1.0    | alpha=`0.1` |
| ComplementNB      | 0.9950   | 0.9903    | 1.0000 | 0.9951   | 1.0    | alpha=`0.1` |

---

## ğŸ§ª Live Testing

The final model was tested with real-world messages.  
âœ… Only 1 message was misclassified out of 21.

### Example Prediction Output:

```bash
ğŸ“© Message: Win a FREE vacation to the Bahamas now! Click to claim.
Confidence: 83.5% Spam
Prediction: ğŸš¨ Spam

ğŸ“© Message: Hey, can you send me the notes from class?
Confidence: 0.18% Spam
Prediction: âœ… Ham
```

## ğŸ§° Tools Used

- **Python:** Pandas, NumPy, Matplotlib, Seaborn  
- **Scikit-learn:** Model building, vectorizers, pipelines, hyperparameter tuning  
- **imbalanced-learn:** SMOTE for handling class imbalance  
- **NLP:** CountVectorizer, TF-IDF, Stopwords removal  
- **Others:** WordCloud, AUC computation, Confusion Matrix visualization  

---

## ğŸŒ©ï¸ Spam vs Ham WordClouds

| Spam Messages                         | Ham Messages                          |
|--------------------------------------|---------------------------------------|
| ![Spam WordCloud](spam_wordcloud.png) | ![Ham WordCloud](ham_wordcloud.png)   |

---

## ğŸ§  Author
- Reza Zare | Data Analyst | NLP & ML Enthusiast
