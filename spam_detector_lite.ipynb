{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXlhs4NtH4CNes9FvvNz7A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mu3m4hYNSRl6"},"outputs":[],"source":["# Spam Detection Project â€“ Lite Version\n","\n","# ---------------------------\n","# ðŸ” Step 1: Load and Preview Dataset\n","# ---------------------------\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","\n","# Load data (replace with your path)\n","df = pd.read_csv(\"sms_spam_detector.csv\", encoding='ISO-8859-1')\n","df = df.rename(columns={'v1': 'label', 'v2': 'text'})\n","df = df[['label', 'text']]\n","\n","# Label distribution\n","sns.countplot(data=df, x='label')\n","plt.title(\"Ham vs Spam Distribution\")\n","plt.show()\n","\n","# ---------------------------\n","# ðŸŒŸ Step 2: Sample Preprocessing Summary\n","# ---------------------------\n","# [Preprocessing done: lowercasing, removing punctuation, tokenizing, stopwords removal]\n","\n","# Create WordClouds (already preprocessed text)\n","spam_words = ' '.join(df[df['label'] == 'spam']['text'])\n","ham_words = ' '.join(df[df['label'] == 'ham']['text'])\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(WordCloud(width=600, height=400, background_color='white').generate(spam_words), interpolation='bilinear')\n","plt.axis('off')\n","plt.title(\"Spam Word Cloud\")\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(WordCloud(width=600, height=400, background_color='white').generate(ham_words), interpolation='bilinear')\n","plt.axis('off')\n","plt.title(\"Ham Word Cloud\")\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# ---------------------------\n","# ðŸ”¢ Step 3: Model Performance Summary\n","# ---------------------------\n","import pandas as pd\n","\n","summary_df = pd.DataFrame([\n","    {\"Model\": \"LogisticRegression\", \"Vectorizer\": \"CountVectorizer\", \"Accuracy\": 0.9989, \"F1 Score\": 0.9989},\n","    {\"Model\": \"MultinomialNB\", \"Vectorizer\": \"CountVectorizer\", \"Accuracy\": 0.9950, \"F1 Score\": 0.9951},\n","    {\"Model\": \"ComplementNB\", \"Vectorizer\": \"CountVectorizer\", \"Accuracy\": 0.9950, \"F1 Score\": 0.9951},\n","])\n","\n","summary_df\n","\n","# ---------------------------\n","# âœ… Step 4: Prediction Example (Cleaned + Deployed)\n","# ---------------------------\n","import joblib\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import MinMaxScaler\n","from scipy.sparse import hstack, csr_matrix\n","import numpy as np\n","import string\n","\n","# Load model components\n","model = joblib.load(\"final_model.pkl\")\n","vectorizer = joblib.load(\"final_vectorizer.pkl\")\n","scaler = joblib.load(\"final_scaler.pkl\")\n","\n","# Define prediction function\n","def predict_message(message):\n","    text = message.lower()\n","    nopunc = ''.join([char for char in text if char not in string.punctuation])\n","    words = nopunc.split()\n","\n","    meta = {\n","        \"clean_text\": ' '.join(words),\n","        \"digit_count\": sum(char.isdigit() for char in message),\n","        \"ex_count\": message.count(\"!\"),\n","        \"has_link\": int(\"http\" in message or \"www\" in message),\n","        \"punct_percent\": round(sum(1 for c in message if c in string.punctuation) / len(message), 3) if len(message) > 0 else 0,\n","    }\n","\n","    X_text = vectorizer.transform([meta['clean_text']])\n","    X_meta = scaler.transform([[meta['digit_count'], meta['ex_count'], meta['has_link'], meta['punct_percent']]])\n","    X_final = hstack([X_text, csr_matrix(X_meta)])\n","\n","    prob = model.predict_proba(X_final)[0][1]\n","    return \"ðŸš¨ Spam\" if prob > 0.05 else \"âœ… Ham\"\n","\n","# Sample prediction\n","print(predict_message(\"Win a FREE iPhone now! Click the link.\"))"]}]}